{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S6_5_1. NLP with FastAI.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbazzi/Data-Science---Fullstack-Bootcamp/blob/master/S6_5_1_NLP_with_FastAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFrmGcyCNodH",
        "colab_type": "text"
      },
      "source": [
        "# Natural Language Processing \n",
        "\n",
        "Avec FastAI, nous pouvons faire de l'analyse de sentiments. Même si vous ne savez pas encore les grands principes mathématiques derrière ce concept, FastAI fonctionne globalement de la même manière que si nous faisions de la détection d'images. Tentons donc de voir ce qu'on peut faire pour prédire le prochain mot d'une phrase à partir de commentaire de films. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Fsy7KDOAMS",
        "colab_type": "text"
      },
      "source": [
        "1. Importez le module ```fast.text```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc_v-tY7B93B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_gsgF4HODZy",
        "colab_type": "text"
      },
      "source": [
        "2. Grâce à la fonction ```untar_data()``` importez le dataset ```URLs.IMDB_SAMPLE```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73sTajfUCS1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dea89dc5-eb90-4ca8-815a-123962f29524"
      },
      "source": [
        "path = untar_data(URLs.IMDB_SAMPLE)\n",
        "path"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.fastai/data/imdb_sample')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYySDWZ0OJk2",
        "colab_type": "text"
      },
      "source": [
        "3. Regardez ce que contient ce dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBLlT4hOCeLK",
        "colab_type": "code",
        "outputId": "f94c5fbe-1491-4f71-9eb8-1be220a510b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "str(path.ls()[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.fastai/data/imdb_sample/texts.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePMGReOtOp5h",
        "colab_type": "text"
      },
      "source": [
        "4. Importez le dataset dans un DataFrame "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKQcMqSWCKk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5b3b056b-7a17-47b8-c755-5d35ddf8f335"
      },
      "source": [
        "df = pd.read_csv(str(path.ls()[0]))\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>This is a extremely well-made film. The acting...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>Every once in a long while a movie will come a...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>Name just says it all. I watched this movie wi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>This movie succeeds at being one of the most u...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text  is_valid\n",
              "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
              "1  positive  This is a extremely well-made film. The acting...     False\n",
              "2  negative  Every once in a long while a movie will come a...     False\n",
              "3  positive  Name just says it all. I watched this movie wi...     False\n",
              "4  negative  This movie succeeds at being one of the most u...     False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG4czw_oOt7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0udjjtzVPPLV",
        "colab_type": "text"
      },
      "source": [
        "5. Séparez votre dataset en train set et un test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeQiqrczPO99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.4, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc9aJWoZOL71",
        "colab_type": "text"
      },
      "source": [
        "6. Créeons un ```DataBunch```. Cette fois ce sera non pas un ```ImageBunch``` mais un ```TextLMDataBunch```. Importez les données via ```from_df```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nntQfvFYPEXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data  = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDbYwJt7Pqhx",
        "colab_type": "text"
      },
      "source": [
        "7. Regardez un premier batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Ivlcb2FN5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "f4bc367c-4540-4e4e-8e94-412deafc7266"
      },
      "source": [
        "data.show_batch()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>xxmaj hollywood , they are no longer in their \" hot chick \" age but more in their \" xxunk xxunk \" age . xxmaj what angered me most about the movie was the main plot line , which pretty much completely xxunk \" xxmaj xxunk &amp; xxmaj xxunk xxmaj do xxmaj america \" ( in which the boys are all xxunk up about some dude offering them money to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3 ) . i watched it as soon as i got home , but i had to watch it again because i kept missing a few parts the first time . xxmaj the second time i watched it , it felt a lot better , and i laughed a lot harder . i 'm definitely going to re - get this on xxup dvd because i xxup have to see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>little ludicrous to me . xxmaj but in the end , i thought the film handled the concept well ( even if some scenes were a little clichéd ) . \\n \\n  xxmaj the cast was quite good , and the two leads seemed to take their roles very seriously . i could n't help thinking , though , that xxmaj xxunk xxmaj turner is a bit of a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>xxmaj my only xxunk are that the plot has a few improbable moments and that some of the stronger xxmaj manchester accents are difficult at times . xxmaj luckily even missing a word here and there wo n't spoil the fun : the primary actors are ideally cast . xxmaj xxunk xxmaj green brings an xxunk smile , a go - for - broke xxunk and an athletic xxunk to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>, xxmaj warner could have come up with a catchy or more appropriate title . \" xxmaj gold or xxmaj grain \" is short and to the point . xxmaj incidentally , i understand there is still plenty of gold in ' them xxunk hills ' , waiting to be xxunk by means other than hydraulic mining . xxbos i saw this movie with some xxmaj indian friends on xxmaj</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hapmUkzCo1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTa2JFTzPtpF",
        "colab_type": "text"
      },
      "source": [
        "8. On va créer modèle qu'on appelle un ```language_model_learner```. Nous verrons plus en détail ce que c'est dans les prochaines sessions. Ajoutez comme paramètre votre ```TextLMDataBunch``` ainsi que l'argument  ```AWS_LSTM```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WxnDglmCrBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = language_model_learner(data,AWD_LSTM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlLzW14fGxc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "16dbc4da-9cca-4237-92db-ae3f2458d266"
      },
      "source": [
        "learner.fit_one_cycle(4)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.579990</td>\n",
              "      <td>3.953307</td>\n",
              "      <td>0.278748</td>\n",
              "      <td>00:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.410491</td>\n",
              "      <td>3.834078</td>\n",
              "      <td>0.290132</td>\n",
              "      <td>00:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.258584</td>\n",
              "      <td>3.802561</td>\n",
              "      <td>0.291025</td>\n",
              "      <td>00:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.155759</td>\n",
              "      <td>3.797661</td>\n",
              "      <td>0.291256</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfiyXPmNCzev",
        "colab_type": "code",
        "outputId": "107da752-2235-4a8a-b75a-49da781a7500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.965628</td>\n",
              "      <td>4.125861</td>\n",
              "      <td>0.273140</td>\n",
              "      <td>20:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.756886</td>\n",
              "      <td>3.986973</td>\n",
              "      <td>0.284301</td>\n",
              "      <td>20:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.603201</td>\n",
              "      <td>3.948684</td>\n",
              "      <td>0.286280</td>\n",
              "      <td>20:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.511753</td>\n",
              "      <td>3.941933</td>\n",
              "      <td>0.285625</td>\n",
              "      <td>20:41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTVCxMBNQX_R",
        "colab_type": "text"
      },
      "source": [
        "9. Nous avons un modèle qui fonctionne ! Tentons de faire une prédiction. Via la méthode ```.predict()```, regardez ce que votre modèle proposerait à la phase \"I loved this movie because\". \n",
        "\n",
        "Précisez que vous voulez au 10 mots après la phrase via l'argument : ```n_words=int```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP782VXUHpo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "403f9073-47b3-4b48-bbb9-d010c14560b4"
      },
      "source": [
        "learner.predict(\"I loved this movie because\", n_words=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I loved this movie because it 's always performed by local people along the way\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIEoZGdZC4Vb",
        "colab_type": "code",
        "outputId": "9fe8908a-eed2-4241-c221-11417e3a2f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I loved this movie because it educational scenes like an opera in the Japanese'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqf2MaXaRSmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}