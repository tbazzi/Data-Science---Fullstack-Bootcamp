{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S7_3_1 Custom Traing with Iris - SOLUTIONS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbazzi/Data-Science---Fullstack-Bootcamp/blob/master/S7_3_1_Custom_Traing_with_Iris_SOLUTIONS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8VyRHgBo_K6",
        "colab_type": "text"
      },
      "source": [
        "# Custom Training with Iris\n",
        "\n",
        "Nous allons cette fois sortir de Keras pour notre boucle d'entrainement. Nous allons créer un réseau de neurones classique qui va pouvoir classer les différentes fleurs Iris. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV7NQ9TLpOWg",
        "colab_type": "text"
      },
      "source": [
        "* Importez les librairies suivantes : \n",
        "    * os \n",
        "    * matplotlib.pyplot \n",
        "    * tensorflow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iXOKac8o6Vq",
        "colab_type": "code",
        "outputId": "6cf5a2c4-99e5-4e32-909b-12f764c38e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0beta1\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt \n",
        "import os "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (3.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.16.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.33.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.12.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0beta1) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0beta1) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0beta1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0beta1) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0beta1) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNPAR51p2ti",
        "colab_type": "text"
      },
      "source": [
        "* Nous allons importer Iris depuis le dataset public que Google Cloud. Utilisez la fonction [`tf.keras.utils.get_file`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file) pour télécharger le dataset iris. \n",
        "\n",
        "Voici l'url du dataset de train : \n",
        "\n",
        "`https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foDYYx06pmID",
        "colab_type": "code",
        "outputId": "8606b7ab-0a25-4377-aabc-74e12505405c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_set_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
        "\n",
        "tf.keras.utils.get_file(\"iris.csv\", \n",
        "                        train_set_url, \n",
        "                        cache_subdir=\"/content\"\n",
        "                        )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/iris.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPMX4vILrFTT",
        "colab_type": "text"
      },
      "source": [
        "* En utilisant `pandas` regardez la tête de votre dataset `iris.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bFkiapfqlRk",
        "colab_type": "code",
        "outputId": "7293d1a9-68fe-4742-9d53-64ee8f5304a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv(\"iris.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>120</th>\n",
              "      <th>4</th>\n",
              "      <th>setosa</th>\n",
              "      <th>versicolor</th>\n",
              "      <th>virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   120    4  setosa  versicolor  virginica\n",
              "0  6.4  2.8     5.6         2.2          2\n",
              "1  5.0  2.3     3.3         1.0          1\n",
              "2  4.9  2.5     4.5         1.7          2\n",
              "3  4.9  3.1     1.5         0.1          0\n",
              "4  5.7  3.8     1.7         0.3          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOTmdFcZrvuB",
        "colab_type": "text"
      },
      "source": [
        "* Le csv que nous avons téléchargé est organisé d'une manière étrange. Voici la structure : \n",
        "  * Le header nous donne la taille du dataset, le nombre de features, les différents noms de classes\n",
        "  * Les lignes qui suivent décrivent chacune des features et la variable cible \n",
        "  \n",
        "  Réorganisez le dataframe pour que vous n'ayez que les features et le classement des variables. Vous garderez le noms des features ainsi que le nom des labels dans deux listes séparées. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqF7fxzXrnAB",
        "colab_type": "code",
        "outputId": "461e4b07-9031-4458-f2f4-39880fae361f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.columns = ['sepal_length',\n",
        "              'sepal_width', \n",
        "              'petal_length', \n",
        "              'petal_width', \n",
        "              'species']\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width  species\n",
              "0           6.4          2.8           5.6          2.2        2\n",
              "1           5.0          2.3           3.3          1.0        1\n",
              "2           4.9          2.5           4.5          1.7        2\n",
              "3           4.9          3.1           1.5          0.1        0\n",
              "4           5.7          3.8           1.7          0.3        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5-YGjfbss2g",
        "colab_type": "code",
        "outputId": "a9002066-c53c-471b-bb7d-ba33cc630880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n",
        "print(\"Target : {}\".format(class_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target : ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSEfq0iItIgE",
        "colab_type": "text"
      },
      "source": [
        "* Nous avons besoin maintenant de mettre notre dataset dans un `tf.data.Dataset`. Pour cela nous avons besoin de : \n",
        "  * Séparez notre dataset en X et y \n",
        "  * Insérez ceci dans un tf.data.Dataset.from_tensor_slices()\n",
        "  \n",
        "Attention pour insérer un DataFrame dans un tf.data.Dataset, vous pouvez insérer techniquement que des objets Numpy. Vous devrez donc utiliser `X.values`, `y.values`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmkqW_bptCJL",
        "colab_type": "code",
        "outputId": "a75845aa-2fe7-45e3-8734-55dcee1f4d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X.values, y.values))\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((4,), ()), types: (tf.float64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJcbFD4suncQ",
        "colab_type": "text"
      },
      "source": [
        "* Nous avons besoin de mélanger notre dataset et de définir un batch_size. \n",
        "  * Ajoutez un `shuffle` à votre dataset \n",
        "  * Ajoutez un batch_size de 16 à votre dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHyYZaW8ukMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.shuffle(len(df))\n",
        "dataset = dataset.batch(16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYHFW-scvFKt",
        "colab_type": "text"
      },
      "source": [
        "* Vérifiez que tout s'est bien passé en regardant un batch de votre dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqGtSBq3vEnU",
        "colab_type": "code",
        "outputId": "1d817d0e-890c-4d30-a028-c5011cffa3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "features, labels = next(iter(dataset))\n",
        "print(features, labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[5.4 3.9 1.7 0.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [6.  3.  4.8 1.8]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [7.6 3.  6.6 2.1]], shape=(16, 4), dtype=float64) tf.Tensor([0 1 0 2 0 0 0 2 1 0 1 0 0 2 0 2], shape=(16,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYyN23n7vp_r",
        "colab_type": "text"
      },
      "source": [
        "* Nous sommes tout bon pour notre dataset, nous allons donc créer un modèle simple de réseau de neurones. En utilisant Keras, définissez le modèle suivant : \n",
        "  * Une première couche qui prend 4 éléments en input et sort 10 output avec Relu comme fonction d'activation\n",
        "  * Une couche cachée qui output 10 neurones avec Relu comme fonction d'activation \n",
        "  * Une dernière couche qui sort 3 outputs et qui utilise softmax comme fonction d'activation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFrpB-31vLCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=10, input_shape=(4,), activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(units=10, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(units=3, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONEiOxO9xasS",
        "colab_type": "text"
      },
      "source": [
        "* En utilisant [`tf.argmax()`](https://www.tensorflow.org/api_docs/python/tf/math/argmax). Sortez les premières prédictions de votre modèle. \n",
        "\n",
        "Attention cependant, celles-ci seront complètement aléatoire puisque nous avons pas commencé de phase d'entrainement. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ2lAFJmw4pO",
        "colab_type": "code",
        "outputId": "3c49bda0-bfbc-4278-e08b-8c6ac3dc9308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y_pred = tf.argmax(model(features), axis=1)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=342166, shape=(16,), dtype=int64, numpy=array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-TjKfUsx4j4",
        "colab_type": "text"
      },
      "source": [
        "* Nous allons devoir définir une fonction de coût. Choisissez une fonction de coût que vous stockerez dans une variable : `loss`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqvq4kqtxFpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXkMWVVt0auE",
        "colab_type": "text"
      },
      "source": [
        "* Testez votre `loss` en mettant en argument un batch de données ainsi qu'un output du modèle sur ce même batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrAdPajVyHXm",
        "colab_type": "code",
        "outputId": "9b067bc7-cba5-4bf7-a143-1cbe1d6a78b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_object(labels, model(features))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=342212, shape=(), dtype=float32, numpy=1.6899251>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxghWlMr0lVl",
        "colab_type": "text"
      },
      "source": [
        "* Il nous reste deux choses à faire avant d'entrainer notre modèle : \n",
        "  1. Mettre en place une fonction qui va garder en mémoire les gradients \n",
        "  2. Mettre en place un optimizer qui va compiler les gradients pour descendre vers un minimum \n",
        "  \n",
        "  \n",
        "Créez une fonction qui prendra trois arguments : `model, inputs, targets`. Cette fonction enregistrera les gradients de votre fonction de coût et retournera deux valeurs : `loss_value, gradients`\n",
        "\n",
        "Pour plus d'informations, regardez cette page [Gradient Tape](https://www.tensorflow.org/api_docs/python/tf/GradientTape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybYGqApZyeTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as t:\n",
        "    loss_value = loss_object(targets, model(inputs))\n",
        "    \n",
        "  return loss_value, t.gradient(loss_value, model.trainable_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAbxlqRU3qJT",
        "colab_type": "text"
      },
      "source": [
        "* Créons maintenant un `optimizer`. On utilisera Adam avec un learning rate de `0.01`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr3zBUds3oAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuc0uLhn7hv8",
        "colab_type": "text"
      },
      "source": [
        "* Appliquez votre fonction `grad` sur un batch de données avec le modèle que vous venez de définir. Stockez vos outputs dans deux variables : `loss_value, grads`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iTYPmMd32Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_value, grads = grad(model, features, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9ri2v8e7rNZ",
        "colab_type": "text"
      },
      "source": [
        "* Regardez les outputs pour être sur que tout s'est bien passé "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REFGSaQK35O6",
        "colab_type": "code",
        "outputId": "b253f965-954e-4a52-cbf3-ac8739874939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(loss_value)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1.6899251, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF4MYPJy4VUE",
        "colab_type": "code",
        "outputId": "7f5efa82-283c-481d-e0bb-b972a85ce6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(grads)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: id=342309, shape=(4, 10), dtype=float32, numpy=\n",
            "array([[ 0.0000000e+00,  0.0000000e+00,  1.0753063e+00,  0.0000000e+00,\n",
            "         0.0000000e+00, -4.4785115e-01,  9.5678739e-02,  0.0000000e+00,\n",
            "         0.0000000e+00, -2.5431864e-02],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  7.7735478e-01,  0.0000000e+00,\n",
            "         0.0000000e+00, -3.1481877e-01,  8.8605568e-02,  0.0000000e+00,\n",
            "         0.0000000e+00, -1.6628528e-02],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  3.0419722e-01,  0.0000000e+00,\n",
            "         0.0000000e+00, -1.4008799e-01, -2.2516211e-02,  0.0000000e+00,\n",
            "         0.0000000e+00, -6.8470403e-03],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  5.4557890e-02,  0.0000000e+00,\n",
            "         0.0000000e+00, -2.7576191e-02, -2.1113236e-02,  0.0000000e+00,\n",
            "         0.0000000e+00, -9.7814866e-04]], dtype=float32)>, <tf.Tensor: id=342308, shape=(10,), dtype=float32, numpy=\n",
            "array([ 0.        ,  0.        ,  0.21679531,  0.        ,  0.        ,\n",
            "       -0.09130178,  0.03481667,  0.        ,  0.        , -0.00489074],\n",
            "      dtype=float32)>, <tf.Tensor: id=342306, shape=(10, 10), dtype=float32, numpy=\n",
            "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00],\n",
            "       [ 0.00000000e+00,  7.94583201e-01,  0.00000000e+00,\n",
            "         5.75787783e-01, -2.95417637e-01,  0.00000000e+00,\n",
            "         6.43726408e-01,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00],\n",
            "       [ 0.00000000e+00,  1.36455670e-01,  0.00000000e+00,\n",
            "         9.75403786e-02, -5.00415638e-02,  0.00000000e+00,\n",
            "         1.09195136e-01,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00],\n",
            "       [ 0.00000000e+00,  5.62136173e-01,  0.00000000e+00,\n",
            "         4.03512865e-01, -2.07020029e-01,  0.00000000e+00,\n",
            "         4.51541007e-01,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00],\n",
            "       [ 0.00000000e+00,  5.99331339e-04,  0.00000000e+00,\n",
            "         4.54283727e-04, -2.33125305e-04,  0.00000000e+00,\n",
            "         5.05714328e-04,  0.00000000e+00,  0.00000000e+00,\n",
            "         0.00000000e+00]], dtype=float32)>, <tf.Tensor: id=342304, shape=(10,), dtype=float32, numpy=\n",
            "array([ 0.        ,  0.2138898 ,  0.        ,  0.1708092 , -0.08767405,\n",
            "        0.        ,  0.18924482,  0.        ,  0.        ,  0.        ],\n",
            "      dtype=float32)>, <tf.Tensor: id=342302, shape=(10, 3), dtype=float32, numpy=\n",
            "array([[ 0.        ,  0.        ,  0.        ],\n",
            "       [-0.23523864,  0.09363423,  0.14160442],\n",
            "       [ 0.        ,  0.        ,  0.        ],\n",
            "       [-1.0829471 ,  0.43887872,  0.6440684 ],\n",
            "       [-0.5168505 ,  0.20878108,  0.3080694 ],\n",
            "       [ 0.        ,  0.        ,  0.        ],\n",
            "       [-0.94627744,  0.38299537,  0.56328213],\n",
            "       [ 0.        ,  0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        ]], dtype=float32)>, <tf.Tensor: id=342300, shape=(3,), dtype=float32, numpy=array([-0.47158566,  0.17668557,  0.2949001 ], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9nHravc8uRb",
        "colab_type": "text"
      },
      "source": [
        "* Nous allons regarder une première itération des gradients avec une loss initiale. En utilisant [`optimizer.iterations`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) et `loss_value` imprimez la value de votre loss à la première itération "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDxzRMq65Cr5",
        "colab_type": "code",
        "outputId": "d6f40560-4d61-4f8b-cf7a-d4af37dd825c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss_value.numpy()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 0, Initial Loss: 1.6899250745773315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2OjtnTF9XsE",
        "colab_type": "text"
      },
      "source": [
        "* Nous avons notre première itération 0, où nous avons pas appliqué notre optimizer. Utilisons le maintenant pour notre seconde itération. Pour cela, utilisez : \n",
        "\n",
        "[`optimizer.apply_gradients(zip(gradients, weights))`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam#apply_gradients)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67KqS5F97WBh",
        "colab_type": "code",
        "outputId": "ca96cce3-aeef-494d-d4ee-47ca5ab3963f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "optimizer.apply_gradients(zip(grads, model.trainable_weights))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwrbB7kv-IwO",
        "colab_type": "text"
      },
      "source": [
        "* Faites une nouvelle prédiction avec vos variables mises à jour et calculez votre loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFQ5DvZs-GyG",
        "colab_type": "code",
        "outputId": "27772118-5588-40e4-bd0b-8072714a803f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss_object(labels, model(features)).numpy()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 1, Initial Loss: 1.5437960624694824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIcp0cGI_mUt",
        "colab_type": "text"
      },
      "source": [
        "* Nous avons tout ce qu'il nous faut pour démarrer un entrainement de notre modèle sur tout le dataset. Pour ce faire vous aurez besoin : \n",
        "\n",
        "1. Définir le nombre d'epochs (RAPPEL : Une epoch est une passe sur tout le dataset)\n",
        "\n",
        "2. Créer une boucle sur le nombre d'epochs \n",
        "\n",
        "3. A l'intérieur de chaque epoch, vous devrez calculer les gradients pour chacune des étapes de votre modèle et les mettre à jour.\n",
        "\n",
        "4. Vous devrez garder quelques statistics en tête et prendre la `loss` moyenne par epoch et `SparseCategoricalAccuracy` comme metric. Voici de la documentation pour vous aider \n",
        "\n",
        "* [tf.keras.metrics.Mean()](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Mean)\n",
        "* [tf.keras.metrics.SparseCategoricalAccuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-5P4XHs-LSQ",
        "colab_type": "code",
        "outputId": "5369b832-ff3f-4cb1-edd6-b89e6ba73943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "# Train_loss_results & train_accuracy_results vont nous permettre\n",
        "# de garder des résultats pour des graphiques \n",
        "\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 201\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  # Training loop - using batches of 16\n",
        "  for x, y in dataset:\n",
        "    # Optimize the model\n",
        "    loss_value, grads = grad(model, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Track progress\n",
        "    epoch_loss_avg(loss_value)  # add current batch loss\n",
        "    # compare predicted label to actual label\n",
        "    epoch_accuracy(y, model(x))\n",
        "\n",
        "  # end epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: Loss: 1.131, Accuracy: 43.333%\n",
            "Epoch 050: Loss: 0.055, Accuracy: 98.333%\n",
            "Epoch 100: Loss: 0.047, Accuracy: 99.167%\n",
            "Epoch 150: Loss: 0.044, Accuracy: 98.333%\n",
            "Epoch 200: Loss: 0.041, Accuracy: 98.333%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWhueg7EB4Am",
        "colab_type": "text"
      },
      "source": [
        "* Puisque vous avez gardé votre loss moyenne par epoch ainsi que votre accuracy, insérez les dans deux graphiques différents "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34jYEBeoBTRw",
        "colab_type": "code",
        "outputId": "996f9610-2886-4e0c-f37c-22d5169df5a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAIdCAYAAAAH9goCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJGiMLbEmSJGmM/h9aw5b2strSFwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "375H67GiPV3k",
        "colab_type": "text"
      },
      "source": [
        "* Evaluons maintenant notre modèle. Pour cela, nous aurons besoin de télécharger le *test_set*  d'iris. Procédez de la même manière qu'au début de cet exercice pour insérer le csv dans un `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54OQ7tv6CGdz",
        "colab_type": "code",
        "outputId": "a0486fb8-10c4-4934-f339-af8fd9da0e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_set_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "tf.keras.utils.get_file(\"iris_test.csv\", \n",
        "                        test_set_url, \n",
        "                        cache_subdir=\"/content\"\n",
        "                        )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/iris_test.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYG7IqwAPtg9",
        "colab_type": "code",
        "outputId": "0b2ac934-1c08-4307-f39f-89f0d9ceaccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df = pd.read_csv(\"iris_test.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>30</th>\n",
              "      <th>4</th>\n",
              "      <th>setosa</th>\n",
              "      <th>versicolor</th>\n",
              "      <th>virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    30    4  setosa  versicolor  virginica\n",
              "0  5.9  3.0     4.2         1.5          1\n",
              "1  6.9  3.1     5.4         2.1          2\n",
              "2  5.1  3.3     1.7         0.5          0\n",
              "3  6.0  3.4     4.5         1.6          1\n",
              "4  5.5  2.5     4.0         1.3          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfJ2pz0JP2WZ",
        "colab_type": "code",
        "outputId": "e5b24ff3-5df5-4d1a-9320-958d89bf3348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "test_set = tf.data.Dataset.from_tensor_slices((X.values, y.values))\n",
        "test_set = test_set.shuffle(len(X))\n",
        "test_set = test_set.batch(16)\n",
        "test_set"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 4), (None,)), types: (tf.float64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x7-V7zLQxdg",
        "colab_type": "text"
      },
      "source": [
        "* Testons maintenant notre modèle sur les données de test. Nous aurons besoin de boucler sur tout le dataset et calculer notre accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlmGwmY5QU5U",
        "colab_type": "code",
        "outputId": "94e9f7fa-af07-4b46-a1c6-8184ea3f56cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy = tf.keras.metrics.Accuracy()\n",
        "\n",
        "for (x, y) in test_set:\n",
        "  logits = model(x)\n",
        "  prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "  test_accuracy(prediction, y)\n",
        "\n",
        "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy: 96.667%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyOabcHAxM-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}