{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S6_5_NLP with Fast AI - SOLUTIONS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbazzi/Data-Science---Fullstack-Bootcamp/blob/master/S6_5_NLP_with_Fast_AI_SOLUTIONS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFrmGcyCNodH",
        "colab_type": "text"
      },
      "source": [
        "# Natural Language Processing \n",
        "\n",
        "Avec FastAI, nous pouvons faire de l'analyse de sentiments. Même si vous ne savez pas encore les grands principes mathématiques derrière ce concept, FastAI fonctionne globalement de la même manière que si nous faisions de la détection d'images. Tentons donc de voir ce qu'on peut faire pour prédire le prochain mot d'une phrase à partir de commentaire de films. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Fsy7KDOAMS",
        "colab_type": "text"
      },
      "source": [
        "1. Importez le module ```fast.text```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc_v-tY7B93B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_gsgF4HODZy",
        "colab_type": "text"
      },
      "source": [
        "2. Grâce à la fonction ```untar_data()``` importez le dataset ```URLs.IMDB_SAMPLE```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73sTajfUCS1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb = untar_data(URLs.IMDB_SAMPLE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYySDWZ0OJk2",
        "colab_type": "text"
      },
      "source": [
        "3. Regardez ce que contient ce dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBLlT4hOCeLK",
        "colab_type": "code",
        "outputId": "7a2e4d91-db62-4149-f78c-71f1a624987a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(imdb.glob(\"*\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imdb_sample/texts.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePMGReOtOp5h",
        "colab_type": "text"
      },
      "source": [
        "4. Importez le dataset dans un DataFrame "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG4czw_oOt7d",
        "colab_type": "code",
        "outputId": "50320de0-a8b0-4c95-dca1-822f4b07550d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "text = pd.read_csv(imdb/'texts.csv')\n",
        "text.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>This is a extremely well-made film. The acting...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>Every once in a long while a movie will come a...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>Name just says it all. I watched this movie wi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>This movie succeeds at being one of the most u...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text  is_valid\n",
              "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
              "1  positive  This is a extremely well-made film. The acting...     False\n",
              "2  negative  Every once in a long while a movie will come a...     False\n",
              "3  positive  Name just says it all. I watched this movie wi...     False\n",
              "4  negative  This movie succeeds at being one of the most u...     False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0udjjtzVPPLV",
        "colab_type": "text"
      },
      "source": [
        "5. Séparez votre dataset en train set et un test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeQiqrczPO99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = np.random.rand(len(text)) < 0.8\n",
        "text_train = text[mask]\n",
        "text_test = text[~mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc9aJWoZOL71",
        "colab_type": "text"
      },
      "source": [
        "6. Créeons un ```DataBunch```. Cette fois ce sera non pas un ```ImageBunch``` mais un ```TextLMDataBunch```. Importez les données via ```from_df```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nntQfvFYPEXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df(imdb, \n",
        "                                  train_df=text_train,\n",
        "                                  valid_df = text_test,\n",
        "                                  text_cols=\"text\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDbYwJt7Pqhx",
        "colab_type": "text"
      },
      "source": [
        "7. Regardez un premier batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hapmUkzCo1h",
        "colab_type": "code",
        "outputId": "0da58041-ca1b-4053-f9ab-504c78915fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>! ! ! xxmaj finally this was directed by the guy who did xxmaj big xxmaj xxunk ? xxmaj must be a replay of xxmaj jonestown - hollywood style . xxmaj xxunk ! xxbos xxmaj this is a extremely well - made film . xxmaj the acting , script and camera - work are all first - rate . xxmaj the music is good , too , though it is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>off with his ' man - eating ' dog behind him . \\n \\n  xxmaj the townsfolk already suspect he is the one behind it all and want his castle burned down . xxmaj the murders first began around the time xxmaj count xxmaj yanos ' older brother , xxmaj count xxmaj igor xxmaj dalmar was horribly burned and killed in a lab accident . \\n \\n  xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>would n't have the nerve to go even 5 feet away from a croc . \\n \\n  xxmaj but , everything in this movie is bad . xxmaj xxunk jokes , people getting eaten , and the skit about the xxmaj president all make the movie one of the worst of all time . \\n \\n  xxmaj it 's a really bad film that you have to stay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>a \" feel good \" movie where you leave the theatre humming \" that 's xxunk \" or repeating some of your favorite lines : \" old man , if you give those dogs another piece of my food , i 'll kick you till you 're dead \" ; \" xxmaj xxunk , bring me the big knife \" , \" who 's dead \" , \" do you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>large change . xxmaj the movie portrays similar xxunk xxmaj first of all the movie starts off with this team that apparently is trying to shoot this \" xxmaj phantom \" guy or whatever , they appear to be a professional team and wear xxunk and shoot mags , xxunk . xxmaj one guy sporting a xxunk . xxmaj not much wrong with the movie but more how it 's</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTa2JFTzPtpF",
        "colab_type": "text"
      },
      "source": [
        "8. On va créer modèle qu'on appelle un ```language_model_learner```. Nous verrons plus en détail ce que c'est dans les prochaines sessions. Ajoutez comme paramètre votre ```TextLMDataBunch``` ainsi que l'argument  ```AWS_LSTM```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WxnDglmCrBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfiyXPmNCzev",
        "colab_type": "code",
        "outputId": "285267a8-0cc2-4179-9f77-c710d9bb090a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "learn.fit_one_cycle(4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.616187</td>\n",
              "      <td>3.993777</td>\n",
              "      <td>0.273465</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.423488</td>\n",
              "      <td>3.870373</td>\n",
              "      <td>0.284026</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.248979</td>\n",
              "      <td>3.831579</td>\n",
              "      <td>0.286593</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.135379</td>\n",
              "      <td>3.826577</td>\n",
              "      <td>0.286077</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTVCxMBNQX_R",
        "colab_type": "text"
      },
      "source": [
        "9. Nous avons un modèle qui fonctionne ! Tentons de faire une prédiction. Via la méthode ```.predict()```, regardez ce que votre modèle proposerait à la phase \"I loved this movie because\". \n",
        "\n",
        "Précisez que vous voulez au 10 mots après la phrase via l'argument : ```n_words=int```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIEoZGdZC4Vb",
        "colab_type": "code",
        "outputId": "6702daea-c422-45ba-8fd9-4c6279363475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(\"I loved this movie because\", n_words=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I loved this movie because i was a fan of all the English movies like 3rd , i'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}